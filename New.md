1. LLM-Driven code generation for web applications using Class Diagram
2.   Chatbot for Bill Passage, Voter Prediction Using BERT and Statistical Model
	1. A web-based chatbot enabling users to analyze and predict bill passage through natural language prompts. A fine-tuned BERT model detects intent from Natural language prompts, while semantic similarity identifies related bills. A statistical model evaluates historical patterns to forecast outcomes and voter probabilities. The chatbot also determines if a specific legislator can vote. By combining AI-driven insights with an intuitive interface, it enhances legislative forecasting, helping policymakers, analysts, and the public understand voting dynamics effortlessly.
3. Fine Tuning BERT model for intent recognition from natural language prompts
4.   An Event-Driven Data Analysis Automation Tool for IoT
5.  Predicting Stock Prices Using Sentiment Analysis and LSTM Networks
	1. Developed a predictive model integrating sentiment analysis and Long Short-Term Memory (LSTM) networks to forecast stock price movements. Utilized historical stock price data alongside sentiment analysis of financial news articles and social media posts to capture market sentiment. Preprocessed textual data to extract sentiment scores, which were combined with numerical stock data. Trained an LSTM model to learn temporal dependencies and predict future stock prices. Achieved improved prediction accuracy by incorporating sentiment information, demonstrating the model's ability to capture the impact of public sentiment on stock market trends.
6.  Emotion Detection in Text Using Transformer Models
	1. Developed a machine learning project utilizing transformer-based models to accurately detect and classify emotions in textual data. Leveraged pre-trained models from the Hugging Face library, fine-tuned on the "Emotions in Text" dataset, which comprises 416,370 labeled tweet snippets across six emotion categories: anger, fear, joy, love, sadness, and surprise. Implemented data preprocessing steps such as lowercasing, tokenization, truncation, and padding to prepare the text for model training. Fine-tuned the DistilBERT model using the AdamW optimizer with a learning rate of 2e-5 and a batch size of 32, applying class weights to address class imbalance. Achieved an overall accuracy of 92.4% on the test set, with detailed analysis revealing higher performance on more frequent classes like "joy" and "sadness." Utilized interpretability techniques to understand model predictions and error patterns, providing insights into the model's decision-making process.
7. Converting Quran and Hadith into RAG for Llama2 and integrating into ReactNative Mobile Application through Python FastAPI backend
8. Automatic Upwork proposal generation and job applying process using Chrome extension and LLM


Supervising
1. Designing Responses schemas for LLM to process documents and respond into specific schemas
2. Blackbox testing test case generation and execution using Agentic AI and LLM
3. Automating Fiverr Gig update using Chrome extension and LLM
4. ETL tool for pipeline generation, execution, and training ML models
5. Generating navigable documentation from code using LLM (CodeNav)
6. Automating Cloud deployment using Agentic AI and LLM
